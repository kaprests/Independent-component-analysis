{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TMA4320 - Blind Source Sepparation with Independent Component Analysis</h1>\n",
    "<p>Notebook and associated data and source code is hosted at: <a href=\"https://github.com/kaprests/TMA4320-project1\">GitHub</a></p>\n",
    "<h3>Gruppe 21 - K.A. Prestsveen og H.V. Skaldebø<h3>\n",
    "<h2>Abstract</h2>\n",
    "<p>This notebook is the first project in TMA4320 at the Norwegian University of Science and Technology. It describes the basic principles of independent component analysis, and demonstrates it by separating mixed sound signals into separate, distinguishable components.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1 - Introduction</h2>\n",
    "The purpose of this project is to simulate the Cocktail party effect (CPE) with blind source separation, using independent component analysis (ICA). The CPE is a psychological effect allowing the human brain to distinguish conversations or sounds from e.g. a noisy room with several different sound sources. The noisy room is simulated with  a provided audiomix of three sources which is sepparated into independent, distinguishable sound clips using ICA. \n",
    "\n",
    "Each signal $j$ of length $T$ is described by a function $s_{j}(t),$ $t  \\epsilon [0,T]$ at time $t$. Combining the signals with weights $a_{ij}$, depending upon the distance from the source, one gets a linear combination $x_{i}$ describing the mixed sound recorded of microphone *i*. In this notebook the number of sources $j$ is assumed to be equal to the number of microphones $i$, making things a little simpler.\n",
    "\n",
    "$$x_{i}(t) = a_{i1}s_{1}(t) + ... + a_{id}s_{d}(t), i = 1, 2, ... , n$$\n",
    "\n",
    "With a digital signal each source and recording will be described by a discrete, sampled signal instead of a continious function like above. The sampled signals from all the sources and the recorded audio of all the microphones can then be described with the $dxN$ matrices <b>s</b> and <b>x</b>, with $d$ being the number of sources or microphones and $N$ the number of discrete signals determined by the length of the sound clip (s) times the sample rate (Hz).\n",
    "\n",
    "$$ \\mathbf{s} = \\begin{bmatrix}\n",
    "    s_{1}(t_{0}) & \\dots & s_{1}(t_{N}) \\\\\n",
    "    s_{2}(t_{0}) & \\dots & s_{2}(t_{N}) \\\\\n",
    "    . & \\dots & . \\\\\n",
    "    . & \\dots & . \\\\\n",
    "    . & \\dots & . \\\\\n",
    "    s_{d}(t_{0}) & \\dots & s_{d}(t_{N})\n",
    "\\end{bmatrix}\n",
    ",  \\mathbf{x} = \\begin{bmatrix}\n",
    "    x_{1}(t_{0}) & \\dots & x_{1}(t_{N}) \\\\\n",
    "    x_{2}(t_{0}) & \\dots & x_{2}(t_{N}) \\\\ \n",
    "    . & \\dots & . \\\\\n",
    "    . & \\dots & . \\\\\n",
    "    . & \\dots & . \\\\\n",
    "    x_{d}(t_{0}) & \\dots & x_{d}(t_{N})\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The number of sources and microphones $d$ will typically be a very small number compared to $N$, for the audio signals used here $d = 3$ and $N = 5000$. The matrix **A** containing the weights $a_{ij}$ is not displayed.\n",
    "\n",
    "\n",
    "<h2>Independent Component Analysis</h2>\n",
    "<b>This is just a very brief review of the basic ideas behind ICA, which is more thoroughly explained in \"Independent component analysis: algorithms and applications\".<a href=\"#article\" id=\"articleref\"><sup>1</sup></a></b>\n",
    "\n",
    "Independent component analysis is, as the name suggests, a way to unmix and reconstruct the original signals given signals mixed in an arbitrary or unknown way. An important assumption of the method is that the signals are statistically independent, and so the analysis is not expected to work if this is not fullfilled. It is also assumed that the signals are non-gaussian, meaning they are not distributed according to the normal distribution.\n",
    "\n",
    "The goal is to find an \"unmix matrix\" $W$ which essentially tries to transform the mixed data back into something resembling the original, unmixed signals, and since the original signals are assumed to be non-gaussian, the idea is to maximize the non-gaussianity of $y(t)$.\n",
    "\n",
    "$$ \\mathbf{y(t)} = \\begin{bmatrix}\n",
    "    W_{1,1} & \\dots & W_{1,d} \\\\\n",
    "    W_{2,1} & \\dots & W_{2,d} \\\\\n",
    "    . & \\dots & . \\\\\n",
    "    . & \\dots & . \\\\\n",
    "    . & \\dots & . \\\\\n",
    "    W_{d,1} & \\dots & W_{d,d}\n",
    "\\end{bmatrix}\n",
    ".\n",
    "\\begin{bmatrix}\n",
    "    x_{1}(t_{0}) & \\dots & x_{1}(t_{N}) \\\\\n",
    "    x_{2}(t_{0}) & \\dots & x_{2}(t_{N}) \\\\ \n",
    "    . & \\dots & . \\\\\n",
    "    . & \\dots & . \\\\\n",
    "    . & \\dots & . \\\\\n",
    "    x_{d}(t_{0}) & \\dots & x_{d}(t_{N})\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Kurtosis and negentropy are two different measurements of non-gaussianity, and to maximize the non-gaussianity of y(t), the algorithm maximizes the kurtosis or negentropy of the unmix matrix $W$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2 - The Algorithm</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.1 - Preparations</h2>\n",
    "\n",
    "Firsly we need to import the data (sound files) that we will be working with and make them playable. The three cells below uploads the provided sound files, utilizing the provided script \"wav_file_loader.py\", and the files are assumed to be placed in <b>.audio/</b>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This cell uploads the files that are to be decomposed.'''\n",
    "\n",
    "import numpy as np\n",
    "from wav_file_loader import read_wavefiles\n",
    "\n",
    "paths = ['audio/mix_1.wav', 'audio/mix_2.wav', 'audio/mix_3.wav']\n",
    "data, sampling_rate = read_wavefiles(paths)\n",
    "num_signals = data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This cell normalizes the signals to a common volume level.'''\n",
    "\n",
    "def normalize_audio(data):\n",
    "    # Scale amplitude s.t. max(data[i]) == 1.\n",
    "    abs_data = np.absolute(data)\n",
    "    maximums = np.amax(abs_data,1)\n",
    "    \n",
    "    # Divide each row by a different vector element:\n",
    "    data = data / maximums.reshape((3,1))\n",
    "    return data\n",
    "\n",
    "data = normalize_audio(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output widgets of the cells below allows playback of the provided mixed audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This cell makes widgets for playing the uploaded clips.'''\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    ipd.display(ipd.Audio(data[i,:], rate=sampling_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.2 - Mixing</h2>\n",
    "\n",
    "The cells in this section is for mixing sepparate, clear audio into noisy clips. This is used to create some custom clips to further test the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_rowsums(A):\n",
    "    '''\n",
    "    Divides each row in A by its sum.\n",
    "    The sum of each row in the result is 1.0.\n",
    "    '''\n",
    "    \n",
    "    the_sum = np.sum(A,1)\n",
    "    A = A / the_sum.reshape((3,1))\n",
    "    return A\n",
    "\n",
    "def random_mixing_matrix(signals, observations):\n",
    "    '''\n",
    "    Creates a random matrix\n",
    "    Each element is a small positive number, not too close to 0.\n",
    "    (1/11, 5/7).\n",
    "    '''\n",
    "    \n",
    "    A = 0.25 + np.random.rand(observations, signals)\n",
    "    return normalize_rowsums(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = random_mixing_matrix(num_signals, num_signals)\n",
    "data_mixed = normalize_audio(A @ data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the widgets outputed by the cell below allows playback of the provided mixed audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data.shape[0]):\n",
    "    ipd.display(ipd.Audio(data[i,:], rate=sampling_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.3 - Custom Sound Clips</h2>\n",
    "\n",
    "The cell below combines the functions from the above two sections(2.1 and 2.2) to upload and mix some audio of our own, and makes the resulting mix playable using the outputted widgets. This is decomposed together with the provided audio when the algorithm is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths1 = ['audio/clip1.wav', 'audio/clip2.wav', 'audio/clip3.wav']\n",
    "data1, sampling_rate1 = read_wavefiles(paths1)\n",
    "num_signals1 = data1.shape[0]\n",
    "\n",
    "B = random_mixing_matrix(num_signals1, num_signals1)\n",
    "data_mixed1 = normalize_audio(B @ data1)\n",
    "\n",
    "for i in range(data1.shape[0]):\n",
    "    ipd.display(ipd.Audio(data_mixed1[i,:], rate=sampling_rate1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.4 - Preprocessing</h2>\n",
    "\n",
    "The following cell contains the preprocessing functions <font color='blue'> center_rows() </font> and <font color='blue'> whiten_rows() </font>. The absolute value of the signals does not matter, and thus we can make calculations easier by transforming the data so that the signals oscillates around an expected value of zero. The first function <font color='blue'> center_rows() </font> takes care of this by subtracting the mean of each row $x_{j}(t_{i})$ from the inputed matrix containing the sampled data, as described in the following equation.\n",
    "\n",
    "$$x_{j}(t_{i}) = x_{j}(t_{i}) - \\dfrac{1}{N} \\sum_{m=1}^N x_{j}(t_{m}), i=1,...,N $$\n",
    "\n",
    "The mixed signals $x_{j}(t)$ are not necessary uncorrelated like the source. The second function <font color='blue'> whiten_rows() </font> therefore transforms the input matrix into a covariance matrix $C$ and finds the inverse square root of $C^{-1/2}$. The \"whitened\" version of our matrix is then the product of $C^{-1/2}$ and our original matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_rows(Z):\n",
    "    \"\"\"\n",
    "    Ensures each row has zero mean.\n",
    "    Takes a matrix of arbitrary shape and subtracts from each row the mean value of that row.\n",
    "    \"\"\"\n",
    "    \n",
    "    # The code returns a dxN-matrix, say Zc, where each row has zero mean\n",
    "    row_means = np.mean(Z, axis=1)\n",
    "    Z_transposed = Z.transpose()\n",
    "    Zc_transposed = Z_transposed - row_means\n",
    "    Zc = Zc_transposed.transpose()\n",
    "    return Zc #, mus\n",
    "\n",
    "\n",
    "def whiten_rows(Z):\n",
    "    \"\"\"\n",
    "    Return whitened version of Z and the matrix for the transform, say Zw, T, where Zw=T*Z\n",
    "    \"\"\"\n",
    "    \n",
    "    # Covariance matrix, C\n",
    "    C = np.cov(Z)\n",
    "    \n",
    "    # The following two statements compute T (inverse square root of C).\n",
    "    U, S, _ = np.linalg.svd(C, full_matrices=False)\n",
    "    T  = U @ np.diag(1 / np.sqrt(S)) @ U.T\n",
    "    \n",
    "    # Finally the withened version of Z, Zw\n",
    "    Zw = np.matmul(T,Z)\n",
    "    \n",
    "    return Zw, T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2.5 - Main Iteration - Maximization of Non-gaussianity(??)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>normalize_rownorms(Z)</h3>\n",
    "This function simply normalises the norms of each rows of the input matrix, and is called as a step in update_w() bewlow. It does this by dividing each row in the inputed matrix Z by its Euclidean norm, so that he norm of each row in the output is equal to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_rownorms(Z):\n",
    "    # Computes Euclidean norm of rows and stores it in a vector(1D numpy array) e_norms\n",
    "    e_norms = np.linalg.norm(Z, axis=1)\n",
    "    \n",
    "    # Scales each row by e_norms \n",
    "    Z_trans = Z.transpose()\n",
    "    Z_norm_trans = Z_trans / e_norms\n",
    "    Z_norm = Z_norm_trans.transpose()\n",
    "    \n",
    "    return Z_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>decorrelate_weights(W)</h3>\n",
    "This is what is reffered to as the orthogonalization step or decorrelation step in \\ref{dummyref lol}. The $dxd$ input matrix $W$ is projected onto an orthogonal matrix by the transformation $Wd = (WW^T)^{-1/2} W$ as described in \\refcitedummyref. The single output argument is the projected $W$-matrix (Wd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decorrelate_weights(W):\n",
    "    # Matrix product of W and its transposed\n",
    "    WW_T = np.matmul(W,W.transpose())\n",
    "    \n",
    "    # Computes T, the inverse square root of WW_T\n",
    "    U, S, _ = np.linalg.svd(WW_T, full_matrices=False)\n",
    "    T = U @ np.diag(1 / np.sqrt(S)) @ U.transpose()\n",
    "    \n",
    "    # Finally computes the decorrelated matrix Wd\n",
    "    Wd = np.matmul(T, W)\n",
    "\n",
    "    return Wd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below simply defines the two measures of non-gaussianity, kurtosis and negentropy, as well as their derivatives, as functions, so they may be passed as input in update_W() below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # kurtosis and derivative as lambda funtions.\n",
    "    kurtosis = lambda u: 4*(u**3)\n",
    "    kurtosis_d = lambda u: 12*(u**2)\n",
    "    \n",
    "    # negentropy and derivative as lambda functions.\n",
    "    negentropy = lambda u: u * np.exp(-((u**2)/2))\n",
    "    negentropy_d = lambda u: -np.exp(-((u**2)/2)) * (u**2 - 1)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>update_w(W, Zcw, func, func_d)</h3>\n",
    "This is the function that calculates the new, less gaussian matrix $W_{k+1}$ from $W_{k}$, and is what is run for each iteration in the final alogirthm. The calculation is done in two steps: the decorrelation step (calling decorrelate_weights()), and the optimization step which increases either negetropy or kurtosis, which ever is passed as input. The input is $W=W_k$ as well as the centered, whitened data Zcw (known as **\\tilde{x}** in \\dummyrefyoo), as well as either kurtosis or negentropy functions and their respective derivative. It returns the new $W = W_{k+1}$.\n",
    "\n",
    "\n",
    "--Bør vi ha ligning og nøyere forklaring her? er litt stress tbh.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_W(W, Zcw, func, func_d):\n",
    "    s_k = np.dot(W, Zcw)\n",
    "        \n",
    "    #Apply kurtosis or negentropy functions and derivatives.\n",
    "    G = func(s_k)\n",
    "    G_d = func_d(s_k)\n",
    "    N = G.shape[1]\n",
    "        \n",
    "    # Computes W_k+1, here called W_p.\n",
    "    W_p = (1/N) * np.dot(G, Zcw.transpose()) - np.matmul(np.diag(np.average(G_d, axis=1)), W)\n",
    "    \n",
    "    # Normalizes rows of W_p (W_k+1).\n",
    "    W_pn = normalize_rownorms(W_p)\n",
    "    \n",
    "    # Orthogonalization step:\n",
    "    W_pnd = decorrelate_weights(W_pn)\n",
    "\n",
    "    return W_pnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Measure of Convergence</h3>\n",
    "This function computes an error estimate for the maximisation iteration, the convergence\n",
    "criterion (delta) given in the provided project note.<a href=\"#pb\" id=\"pbref\"><sup>2</sup></a><br/>\n",
    "$$\\delta = \\max\\limits_{1\\leq i\\leq d} \\left(1- \\sum_{j=1}^d (\\mathbf{W}_{k})_{ij}(\\mathbf{W}_{k-1})_{ij} \\right)$$\n",
    "Input: W1 is the previous iterate, and W2 is the one just computed.<br/>\n",
    "Output: The quantity delta which is used to determine when the iterations has reached sufficient convergence.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_of_convergence(W1, W2):\n",
    "    \n",
    "    a_s = np.absolute(np.sum(np.multiply(W2, W1), axis=1))\n",
    "    delta = np.absolute(np.amax((1-a_s)))\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>fast_ICA</h3>\n",
    "This is the function that ties everything together and runs the iteration and produces the final, unmixed audio signals. It simply utilieses the functions defined above and is explained through the comments.\n",
    "\n",
    "<b>Input: Z: unprocessed data.</b><br>\n",
    "          signals_to_find: in our case, always d the number of sources.<br>\n",
    "          tol: the tolerance, default value 1.0e-10.<br>\n",
    "          max_iter: max number of iterations, abort after max_iter iterations if not converged, (to avoid infinite loop).<br>\n",
    "           Which function to measure gaussanity (kurtosis or negentropy) and derivative.<br>\n",
    "           \n",
    "<b>Output: Z_ica:</b> <br>\n",
    "        the separated signals (dxN matrix, approximating the sources).<br>\n",
    "        W_p: the final converged W-matrix (dxd).<br>\n",
    "        number_of_iter: how many iterations before reaching convergence.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "tol_default = 1e-10\n",
    "\n",
    "def fast_ICA(Z, signals_to_find, func, func_d, tol=tol_default, max_iter=100):\n",
    "    \"\"\" \n",
    "    \n",
    "    \"\"\"\n",
    "   \n",
    "    # center the rows of Z\n",
    "    Z_cent = center_rows(Z)\n",
    "\n",
    "    # whiten the centered rows\n",
    "    Z_cent_wit, T = whiten_rows(Z_cent)\n",
    " \n",
    "    # Put W_0 = W to a random initial value and normalise the rows to length 1\n",
    "    M = Z_cent.shape[0]\n",
    "    W_0 = np.random.rand(M, M)\n",
    "    W_0 = normalize_rowsums(W_0)\n",
    "    \n",
    "    # Initialise some variables to prepare for the while-loop (such as delta)\n",
    "    delta = tol + 1\n",
    "    number_of_iter = 0\n",
    "\n",
    "    # while delta>tol and number_of_iterations < max_iter:\n",
    "    # an iteration to get a new W-iterate \n",
    "    # the error estimate to update delta\n",
    "\n",
    "    while delta > tol and number_of_iter < max_iter:\n",
    "        W_p  = update_W(W_0, Z_cent_wit, func, func_d)\n",
    "        delta = measure_of_convergence(W_0, W_p)\n",
    "        W_0 = W_p\n",
    "        number_of_iter += 1\n",
    "        \n",
    "    # Clean up, check if converged or max_iter attained\n",
    "    if number_of_iter == max_iter:\n",
    "        print('max_iter using reached \\ndelta: ', delta)\n",
    "        \n",
    "    else:\n",
    "        Z_ica = np.matmul(W_p, Z_cent_wit)\n",
    "        return Z_ica, W_p, number_of_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Runs the code and sepparates the audio!\n",
    "'''\n",
    "# Sepparates provided mix:\n",
    "print('Provided mix: \\n')\n",
    "\n",
    "print('kurtosis: \\n')\n",
    "Z_ica_kur, W_ica_kur, num_iter_kur = fast_ICA(data, 3, kurtosis, kurtosis_d)\n",
    "print('Numer of iterations: ', num_iter_kur, '\\n')\n",
    "\n",
    "print('negentropy: \\n')\n",
    "Z_ica_neg, W_ica_neg, num_iter_neg = fast_ICA(data, 3, negentropy, negentropy_d)\n",
    "print('Numer of iterations: ', num_iter_neg, '\\n')\n",
    "\n",
    "\n",
    "# Sepparates custom mix:\n",
    "print('Custom mix: \\n')\n",
    "\n",
    "print('kurtosis: \\n')\n",
    "Z_ica_kur1, W_ica_kur1, num_iter_kur1 = fast_ICA(data1, 3, kurtosis, kurtosis_d)\n",
    "print('Numer of iterations: ', num_iter_kur, '\\n')\n",
    "\n",
    "print('negentropy: \\n')\n",
    "Z_ica_neg1, W_ica_neg1, num_iter_kur1 = fast_ICA(data1, 3, negentropy, negentropy_d)\n",
    "print('Numer of iterations: ', num_iter_kur, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3 - Results</h2>\n",
    "\n",
    "Below both the original mixed and the unmixed files can be played back and compared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The provided mixed audio:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data.shape[0]):\n",
    "    ipd.display(ipd.Audio(data[i,:], rate=sampling_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The provided audio unmixed(kurtosis):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data.shape[0]):\n",
    "    ipd.display(ipd.Audio(Z_ica_kur[i,:], rate=sampling_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The provided audio unmixed(negentropy):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data.shape[0]):\n",
    "    ipd.display(ipd.Audio(Z_ica_neg[i,:], rate=sampling_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The custom audio mixed:</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data1.shape[0]):\n",
    "    ipd.display(ipd.Audio(data_mixed1[i,:], rate=sampling_rate1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The custom audio unmixed(kurtosis):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data1.shape[0]):\n",
    "    ipd.display(ipd.Audio(Z_ica_kur1[i,:], rate=sampling_rate1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The custom audio unmixed(negentropy):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data1.shape[0]):\n",
    "    ipd.display(ipd.Audio(Z_ica_neg1[i,:], rate=sampling_rate1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Discussion and Conclusion</h2>\n",
    "Both the provided and custom audio was succesfully unmixed using the algorithm. Neat-o. \n",
    "\n",
    "By listening to the audio clips there is no immidiate difference in sepparation quality between runs using kurtosis compared to negentropy, they both generate fairly clear, separated audio with only some background noise. Performance wise the immediate impression is again that they're pretty equal, on single runs, the number of iterations using the two measurments of non-gaussianity also seems be fairly similar, and in many cases even the same. Running the separation many times though revealed that negetropy had a tendecy to perform slightly better. The code in the cell below was used to run the algoritm 100 times for both audio mixes with both kurtosis and negentropy, plotting the number of iterations in bar plots, and calculating the average number of iterations. This discussion is based on averages and plots from a prerun of the code below, which is now commented out. Uncommenting and running the cell below should produce similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This code may take a long time to run depending on chosen value for num_iter.\n",
    "\n",
    "It is also somewhat sloppy written as it will crash in the unlucky case of fast_ICA getting a run of \n",
    "more than 25 iterations to reach convergence.\n",
    "\n",
    "Uncomment code below to generate own figures. Pregenerated figures at at the bottom.\n",
    "'''\n",
    "\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "num_iter = 100;\n",
    "x_vec = np.linspace(1,25,25)\n",
    "\n",
    "# provided audio\n",
    "num_iter_vec_kur = np.zeros(num_iter)\n",
    "num_iter_vec_neg = np.zeros(num_iter)\n",
    "\n",
    "# custom audio\n",
    "num_iter_vec_kur1 = np.zeros(num_iter)\n",
    "num_iter_vec_neg1 = np.zeros(num_iter)\n",
    "\n",
    "# provided audio\n",
    "y_vec_kur = np.zeros(25)\n",
    "y_vec_neg = np.zeros(25)\n",
    "\n",
    "# custom audio\n",
    "y_vec_kur1 = np.zeros(25)\n",
    "y_vec_neg1 = np.zeros(25)\n",
    "\n",
    "print('finishes at: ', num_iter)\n",
    "print('progress: ', end='')\n",
    "for i in range(num_iter):\n",
    "    # provided audio\n",
    "    Z_ica_kur, W_ica_kur, num_iter_kur = fast_ICA(data, 3, kurtosis, kurtosis_d)\n",
    "    Z_ica_neg, W_ica_neg, num_iter_neg = fast_ICA(data, 3, negentropy, negentropy_d)\n",
    "    \n",
    "    num_iter_vec_kur[i] = num_iter_kur\n",
    "    num_iter_vec_neg[i] = num_iter_neg\n",
    "\n",
    "    # custom audio\n",
    "    Z_ica_kur1, W_ica_kur1, num_iter_kur1 = fast_ICA(data1, 3, kurtosis, kurtosis_d)\n",
    "    Z_ica_neg1, W_ica_neg1, num_iter_neg1 = fast_ICA(data, 3, negentropy, negentropy_d)\n",
    "    \n",
    "    num_iter_vec_kur1[i] = num_iter_kur1\n",
    "    num_iter_vec_neg1[i] = num_iter_neg1\n",
    "    \n",
    "    # provided audio\n",
    "    y_vec_kur[num_iter_kur] += 1\n",
    "    y_vec_neg[num_iter_neg] += 1\n",
    "    \n",
    "    #custom audio\n",
    "    y_vec_kur1[num_iter_kur] += 1\n",
    "    y_vec_neg1[num_iter_neg] += 1\n",
    "    \n",
    "    # progression\n",
    "    print(i+1, end='')\n",
    "\n",
    "print(\"Mean value of Provided audio - Kurtosis: \", np.mean(num_iter_vec_kur))\n",
    "print(\"Mean value of Provided audio - Negentropy: \", np.mean(num_iter_vec_neg))\n",
    "print(\"Mean value of Custom audio - Kurtosis: \", np.mean(num_iter_vec_kur1))\n",
    "print(\"Mean value of Custom audio - Negentropy: \", np.mean(num_iter_vec_neg1))\n",
    "\n",
    "plt.bar(x_vec, y_vec_kur)\n",
    "plt.title(\"Provided audio - Kurtosis\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Number of occurences\")\n",
    "#plt.savefig(\"pa_kur.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.bar(x_vec, y_vec_neg)\n",
    "plt.title(\"Provided audio - Negentropy\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Number of occurences\")\n",
    "#plt.savefig(\"pa_neg.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.bar(x_vec, y_vec_kur1)\n",
    "plt.title(\"Custom audio - Kurtosis\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Number of occurences\")\n",
    "#plt.savefig(\"ca_kur.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.bar(x_vec, y_vec_neg1)\n",
    "plt.title(\"Custom audio - Negentropy\")\n",
    "plt.xlabel(\"Number of iterations\")\n",
    "plt.ylabel(\"Number of occurences\")\n",
    "#plt.savefig(\"ca_neg.png\")\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presaved figures showing bar diagrams of the occurence of iteration numbers for the algorithm using both kurtosis and negentropy, giving an impression of the efficiency of the two measurments. <br>\n",
    "![title](pa_kur.png)\n",
    "![title](pa_neg.png)\n",
    "![title](ca_kur.png)\n",
    "![title](ca_neg.png)\n",
    "To more easily interpret the results, the mean value of iterations was also calculated in the code. For our run the mean values were the following:<br>\n",
    "- Provided audio, kurtosis:  9.78 <br>\n",
    "- Provided audio, negentropy:  8.44 <br>\n",
    "- Custom audio, kurtosis:  14.78 <br>\n",
    "- Custom audio, negentropy:  8.55 <br>\n",
    "\n",
    "It becomes apparent from the figures and the mean values that negentropy performs slighly better than kurtosis. Additionally it seems negentropy is more adaptive, considering the small change in iterations compared to kurtosis for the custom audio. This implies negentropy has an easier time unmixing more complex signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>References</h2>\n",
    "    <a id=\"article\" href=\"#articleref\"><sup>1</sup></a> A. Hyvärinen and E. Oja, Independent component analysis: algorithms and applications, Neural networks 13 (2000) 411–413.<br/>\n",
    "    <a id=\"pb\" href=\"#pbref\"><sup>2</sup></a> B. Owren, TMA4320 – våren 2019, Prosjekt 1: Blind source separation, 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
